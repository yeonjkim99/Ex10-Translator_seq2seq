{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54187839",
   "metadata": {},
   "source": [
    "# Ex10. 프로젝트 : 단어 Level로 번역기 업그레이드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01561006",
   "metadata": {},
   "source": [
    "## 0. 환경설정 및 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be366d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir -p ~/aiffel/translator_seq2seq/data\n",
    "# ! mkdir -p ~/aiffel/translator_seq2seq/models\n",
    "# ! wget https://www.manythings.org/anki/fra-eng.zip\n",
    "# ! mv fra-eng.zip  ~/aiffel/translator_seq2seq/data\n",
    "# ! cd ~/aiffel/translator_seq2seq/data && unzip fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d56692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d70f092",
   "metadata": {},
   "source": [
    "## 1. 정제, 정규화, 전처리 (영어, 프랑스어 모두!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df393f5a",
   "metadata": {},
   "source": [
    "### 1-1. 전처리 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78526d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ascii(s):\n",
    "    # 프랑스어 악센트(accent) 삭제\n",
    "    # 예시 : 'déjà diné' -> deja dine\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(sent):\n",
    "    # 악센트 제거 함수 호출\n",
    "    sent = to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백 추가.\n",
    "    # ex) \"I am a student.\" => \"I am a student .\"\n",
    "    sent = re.sub(r\"([?!,.])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \"?\", \"!\", \",\", \".\", \"'\") 이들을 제외하고는 전부 공백으로 변환.\n",
    "    sent = re.sub(r\"[^a-zA-Z?!,.']+\", r\" \", sent)\n",
    "\n",
    "    # 다수 개의 공백을 하나의 공백으로 치환\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c88c1dd",
   "metadata": {},
   "source": [
    "### 1-2. 데이타 로딩,불필요한 프랑스어 액센트 삭제, 불필요한 구두점 제거 및 시작토큰/종료토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d46f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data(num_samples):\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    with open(\"fra.txt\", \"r\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line)\n",
    "            decoder_input.append(tar_line_in)\n",
    "            decoder_target.append(tar_line_out)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563c28e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력 : [['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!'], ['run', '!'], ['run', '!']]\n",
      "디코더의 입력 : [['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.'], ['<sos>', 'cours', '!'], ['<sos>', 'courez', '!'], ['<sos>', 'prenez', 'vos', 'jambes', 'a', 'vos', 'cous', '!'], ['<sos>', 'file', '!']]\n",
      "디코더의 레이블 : [['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>'], ['prenez', 'vos', 'jambes', 'a', 'vos', 'cous', '!', '<eos>'], ['file', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "num_samples = 33000\n",
    "\n",
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data(num_samples)\n",
    "print('인코더의 입력 :',sents_en_in[:10])\n",
    "print('디코더의 입력 :',sents_fra_in[:10])\n",
    "print('디코더의 레이블 :',sents_fra_out[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55762bc2",
   "metadata": {},
   "source": [
    "#### 데이터에대한 전처리가 잘 수행되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c510f85",
   "metadata": {},
   "source": [
    "## 2. 띄어쓰기 단위로 토크나이징, 정수 인코딩 및 패딩 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f4ea79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더의 입력의 크기(shape) : (33000, 7)\n",
      "디코더의 입력의 크기(shape) : (33000, 15)\n",
      "디코더의 레이블의 크기(shape) : (33000, 15)\n",
      "\n",
      "[[ 38   2  85   1   0   0   0]\n",
      " [420   1   0   0   0   0   0]\n",
      " [316 680   1   0   0   0   0]\n",
      " [316 680   1   0   0   0   0]\n",
      " [316  14   1   0   0   0   0]\n",
      " [316  14   1   0   0   0   0]\n",
      " [316  14   1   0   0   0   0]\n",
      " [316  14   1   0   0   0   0]\n",
      " [316  14   1   0   0   0   0]\n",
      " [ 48 488  20   0   0   0   0]]\n",
      "\n",
      "[[   2   25  220    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  399 1230 5114    1    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2 5115   82  485    7    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  805   13  485    7    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  528    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  470   26    7    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  528   26    7    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  528   99    7    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  470   99    7    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2   20 2246    7    0    0    0    0    0    0    0    0    0    0\n",
      "     0]]\n",
      "\n",
      "[[  25  220    1    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 399 1230 5114    1    3    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [5115   82  485    7    3    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 805   13  485    7    3    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 528    1    3    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 470   26    7    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 528   26    7    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 528   99    7    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 470   99    7    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [  20 2246    7    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)                        # 띄어쓰기 단위로 토크나이징\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)  # 정수 인코딩\n",
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")  # 패딩 진행  \n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")\n",
    "\n",
    "print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n",
    "print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n",
    "print('디코더의 레이블의 크기(shape) :',decoder_target.shape)\n",
    "\n",
    "print()\n",
    "print(encoder_input[1000:1010])\n",
    "print()\n",
    "print(decoder_input[1000:1010])\n",
    "print()\n",
    "print(decoder_target[1000:1010])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358e68b",
   "metadata": {},
   "source": [
    "#### 토크나이징, 정수 인코딩 및 패딩까지 잘 진행되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f6396",
   "metadata": {},
   "source": [
    "## 3. 영어, 프랑스어 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1e583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4769, 프랑스어 단어 집합의 크기 : 8728\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30355f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어장을 만듦, 예측값과 실제값을 비교하는데 사용\n",
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word\n",
    "tar_to_index = tokenizer_fra.word_index\n",
    "index_to_tar = tokenizer_fra.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe11228",
   "metadata": {},
   "source": [
    "### 3-5. 전체 데이타 33000개 중 3000개를 validation용으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ec19ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "랜덤 시퀀스 : [21858 12609 12035 ... 21096 15230  6793]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print('랜덤 시퀀스 :',indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f69209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋의 순서로 지정 (기존과 다른 순서로 섞임)\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdfd6d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 source 데이터의 크기 : (30000, 7)\n",
      "훈련 target 데이터의 크기 : (30000, 15)\n",
      "훈련 target 레이블의 크기 : (30000, 15)\n",
      "테스트 source 데이터의 크기 : (3000, 7)\n",
      "테스트 target 데이터의 크기 : (3000, 15)\n",
      "테스트 target 레이블의 크기 : (3000, 15)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n",
    "print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n",
    "print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n",
    "print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n",
    "print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n",
    "print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9d6f60",
   "metadata": {},
   "source": [
    "## 4. 임베딩 층(Embedding layer) 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa8786",
   "metadata": {},
   "source": [
    "### 4-1. 모델 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007fa9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "hidden_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03188769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(src_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(hidden_units, dropout = 0.4, recurrent_dropout=0.4, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd725507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 128)    610432      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1117184     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 128)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 128)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 128), (None, 131584      masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 128),  131584      masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8728)   1125912     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,116,696\n",
      "Trainable params: 3,116,696\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, hidden_units) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(hidden_units, dropout = 0.4, recurrent_dropout=0.4, return_sequences=True, return_state=True) \n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# 모델의 입력과 출력을 정의.\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81431a89",
   "metadata": {},
   "source": [
    "### 4-2. 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b080ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 31s 109ms/step - loss: 2.8095 - val_loss: 1.8529\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 25s 104ms/step - loss: 1.7452 - val_loss: 1.6542\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 1.6047 - val_loss: 1.5640\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 1.5135 - val_loss: 1.4733\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 1.3994 - val_loss: 1.3539\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 1.2786 - val_loss: 1.2581\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 24s 104ms/step - loss: 1.1865 - val_loss: 1.1899\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 25s 104ms/step - loss: 1.1143 - val_loss: 1.1398\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 25s 107ms/step - loss: 1.0540 - val_loss: 1.0976\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 1.0026 - val_loss: 1.0625\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 25s 106ms/step - loss: 0.9550 - val_loss: 1.0312\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 24s 104ms/step - loss: 0.9118 - val_loss: 0.9976\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 25s 105ms/step - loss: 0.8705 - val_loss: 0.9700\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.8331 - val_loss: 0.9482\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.7969 - val_loss: 0.9249\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 25s 106ms/step - loss: 0.7634 - val_loss: 0.9003\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 0.7318 - val_loss: 0.8832\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.7011 - val_loss: 0.8631\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.6734 - val_loss: 0.8455\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.6473 - val_loss: 0.8311\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 25s 106ms/step - loss: 0.6218 - val_loss: 0.8160\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.5983 - val_loss: 0.8028\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 0.5763 - val_loss: 0.7924\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 24s 104ms/step - loss: 0.5550 - val_loss: 0.7786\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 25s 106ms/step - loss: 0.5348 - val_loss: 0.7677\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.5152 - val_loss: 0.7592\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 25s 105ms/step - loss: 0.4973 - val_loss: 0.7510\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 0.4800 - val_loss: 0.7404\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 25s 104ms/step - loss: 0.4634 - val_loss: 0.7309\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.4481 - val_loss: 0.7234\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.4338 - val_loss: 0.7175\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 0.4190 - val_loss: 0.7151\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 0.4056 - val_loss: 0.7060\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 24s 104ms/step - loss: 0.3938 - val_loss: 0.6994\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.3814 - val_loss: 0.6949\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.3709 - val_loss: 0.6935\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.3603 - val_loss: 0.6863\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 24s 104ms/step - loss: 0.3506 - val_loss: 0.6847\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 25s 105ms/step - loss: 0.3399 - val_loss: 0.6807\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.3312 - val_loss: 0.6754\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 0.3233 - val_loss: 0.6739\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 25s 104ms/step - loss: 0.3143 - val_loss: 0.6729\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.3069 - val_loss: 0.6694\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.3007 - val_loss: 0.6679\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 24s 104ms/step - loss: 0.2936 - val_loss: 0.6643\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 24s 104ms/step - loss: 0.2869 - val_loss: 0.6640\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.2804 - val_loss: 0.6646\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 0.2739 - val_loss: 0.6625\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 24s 104ms/step - loss: 0.2688 - val_loss: 0.6616\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 24s 104ms/step - loss: 0.2631 - val_loss: 0.6597\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947469ac",
   "metadata": {},
   "source": [
    "### 4-3. 모델 훈련결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4bfaf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92269838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# bo는 파란색 점\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 파란색 실선\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b2687",
   "metadata": {},
   "source": [
    "#### Validation loss가 epoch 10 (1.1755)까지 급격히 떨어진 이후 epoch 50 (0.7291)까지 완만히 떨어지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a493361",
   "metadata": {},
   "source": [
    "## 5. 테스트 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3a278e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 128)         610432    \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 128), (None, 128) 131584    \n",
      "=================================================================\n",
      "Total params: 742,016\n",
      "Trainable params: 742,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 인코더\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4e36e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1117184     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 128),  131584      embedding_1[1][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8728)   1125912     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,374,680\n",
      "Trainable params: 2,374,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계 시작\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_units,))\n",
    "decoder_state_input_c = Input(shape=(hidden_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단어 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "# 수정된 디코더\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72c78ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 마지막 시점의 상태(은닉 상태, 셀 상태)를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # SOS_token에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "            len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eac66052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_src(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0):\n",
    "            sentence = sentence + index_to_src[encoded_word] + ' '\n",
    "    return sentence\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq_to_tar(input_seq):\n",
    "    sentence = ''\n",
    "    for encoded_word in input_seq:\n",
    "        if(encoded_word != 0 and encoded_word != tar_to_index['<sos>'] and encoded_word != tar_to_index['<eos>']):\n",
    "            sentence = sentence + index_to_tar[encoded_word] + ' '\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "536cfc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력문장 : everyone can play . \n",
      "정답문장 : tout le monde peut y jouer . \n",
      "번역문장 : tout le monde le francais . \n",
      "-----------------------------------\n",
      "입력문장 : come over . \n",
      "정답문장 : venez chez moi ! \n",
      "번역문장 : venez ici . \n",
      "-----------------------------------\n",
      "입력문장 : forget what i said . \n",
      "정답문장 : oubliez ce que j'ai dit ! \n",
      "번역문장 : oublie ce que j'ai dit . \n",
      "-----------------------------------\n",
      "입력문장 : wash everything . \n",
      "정답문장 : lave tout . \n",
      "번역문장 : nettoie tout . \n",
      "-----------------------------------\n",
      "입력문장 : tom has red hair . \n",
      "정답문장 : tom a les cheveux roux . \n",
      "번역문장 : tom a les cheveux rouges . \n"
     ]
    }
   ],
   "source": [
    "# 테스트 해보기\n",
    "for seq_index in [500,1000,1500,2000,2500]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    \n",
    "    print(35 * \"-\")\n",
    "    print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n",
    "    print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n",
    "    print(\"번역문장 :\",decoded_sentence[1:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d7e8f",
   "metadata": {},
   "source": [
    "## 한글로 번역 (구글번역)하여 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab255eaf",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "입력문장 : everyone can play . (모두가 재생할 수 있습니다)\n",
    "\n",
    "정답문장 : tout le monde peut y jouer . (누구나 재생할 수 있습니다)\n",
    "\n",
    "번역문장 : tout le monde le francais . (모두 프랑스)\n",
    "\n",
    "-----------------------------------\n",
    "입력문장 : come over . (이리와)\n",
    "\n",
    "정답문장 : venez chez moi ! (집으로와)\n",
    "\n",
    "번역문장 : venez ici . (여기와)\n",
    "\n",
    "-----------------------------------\n",
    "입력문장 : forget what i said . (내가 말한 건 잊어)\n",
    "\n",
    "정답문장 : oubliez ce que j'ai dit ! (내가 말한 건 잊어)\n",
    "\n",
    "번역문장 : oublie ce que j'ai dit . (내가 말한 건 잊어)\n",
    "\n",
    "-----------------------------------\n",
    "입력문장 : wash everything . (모든 것을 씻다)\n",
    "\n",
    "정답문장 : lave tout . (모든 것을 씻다)\n",
    "\n",
    "번역문장 : nettoie tout . (모든 것을 청소)\n",
    "\n",
    "-----------------------------------\n",
    "입력문장 : tom has red hair . (톰은 빨간 머리를 하고 있다)\n",
    "\n",
    "정답문장 : tom a les cheveux roux . (톰은 빨간 머리를 하고 있다)\n",
    "\n",
    "번역문장 : tom a les cheveux rouges . (톰은 빨간 머리를 하고 있다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935735e",
   "metadata": {},
   "source": [
    "#### 번역기가 기능적으로 잘 작동하고 있고 30,000개의 데이타로 20여분 훈련한 성과치곤 우수한 편이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c545e",
   "metadata": {},
   "source": [
    "## 회고\n",
    "### 이번 프로젝트에서 어려웠던 점\n",
    "\n",
    "model.fit 과정에서 \"valueerror: shapes (none, 14) and (none, 14, 11164) are incompatible\"가 발생 하였는데 해결하느라 무척 애를 먹었다. 구글링, 유튜브 검색을 아무리 해봐도 해결하지 못하다가 우연히 구글링에서 답을 찾았다. model.compile시 loss function을 one-hot-encoding시 적용하는 \"categorical_crossentropy\"에서 label값이 정수인 경우 사용하는 \"sparse_categorical_crossentropy\"로 바꾸어주니 해결되었다. \n",
    "\n",
    "### 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점\n",
    "\n",
    "앞부분 sample이 상대적으로 짧은문장으로 되어있어 중간부분에서 선택해 보았는데 전처리 과정 중 대문자를 소문자로 바꾸어주는 line.lower() 기능이 작동되지 않았다. 아무리 생각해 봐도 이유를 모르겠다.\n",
    "\n",
    "### 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "\n",
    "1. Validation loss가 지속적으로 우하향하지 않아 overfitting이 발생한다고 보아 dropout 및 recurrent_dropout을 적용하였다. 다소 개선되었으나 training loss가 꾸준히 줄어드는 많큼 줄어들지 않는다.\n",
    "2. optimizer를 rmsprop에서 보편적으로 많이 사용하는 adam으로 바꾸었다.\n",
    "3. embedding_dim, hidden_units 및 batch_size 등을 바꾸어 보았다.\n",
    "\n",
    "### 만약에 루브릭 평가 관련 지표를 달성 하지 못했을 때, 이유에 관한 추정\n",
    "\n",
    "번역성능 개선을 위하여 Sample 양을 늘리고 싶었으나 33,000개를 사용하라는 조건이 있어 시도하지 않았다.\n",
    "\n",
    "### 자기 다짐\n",
    "\n",
    "아직 모델작성 및 성능개선 방법이 미숙하다. 첫술에 배부르랴. 앞으로의 과정도 열심히 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e2b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
